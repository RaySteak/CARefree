Camera:
- By tinkering with the camera we can notice that it can only output 2 resolutions (QVGA and VGA),
and 2 color formats (RGB565 and grayscale). By default, VGA at RGB565 is out of question as
the buffer needed would be larger than the RAM memory the board has.
- How do we choose from the remaining 3 possibilities then? Well, initially, it would be ideal to
use the VGA grayscale setting (second highest memory usage after RGB565 VGA) since colours
don't really help us as the camera has pretty bad colour recognition (as tested). Still, this
would leave us with very little remaining memory, since the FreeRTOS components already eat up
some memory. We don't need that high of resolution anyway, as QVGA (320 x 240 is) more than enough
and even most big classification models use a smaller input size than this. As already mentioned,
grayscale would be preferable, but the built-in MSR model takes as input 3-channel RGB images, so
we will choose RGB565 QVGA and grayscale it before sending to the edge (combined with jpg
conversion and/or further downscaling)
- It seems that with QVGA RGB565, applying 4-size average pooling causes very bad noise artifacts,
and just picking the top-left value is preferable and yields better results (fixed, look 2 bullet
points ahead and in the avg_pool_rgb565 for explanation of bug).
- Well, as it turns out, the camera can also do QQVGA (160 * 240). Since we were already doing
downscaling to QQQVGA (with 4-size pooling kernel), and having the impossibility to send QQVGA
images to the server when taking QVGA images as it would require too much RAM storing both a QVGA
and QQVGA image, we will pick QQVGA as the resolution of choice as it is favourable from every
point of view for the grayscale case. Problem is, for the RGB565 case for the the built-in face
detection model, it doesn't like to receive QVGA as input as it is too small for it. Upscaling it
to fit the minimum size would use up too much memory as we would be roughly in the QQVGA + QVGA
images at once AND in the RGB565 format.
- There was a bug in the average pool function for RGB565 images related to the fact that RGB565
is actually big endian. While fixing this bug, I also found that if I want to use face detection
anymore I have to disable MQTT (by commenting the initialization function) as it seemed to use up
quite some RAM and inference with the face detection model would crash. So, there is no possibility
of testing this method with the whole pipeline anymore. Still, the implementation should work like
a breeze for boards with enough memory.

Labeling data:
Using a pre-trained model from huggingface running on the edge as ground truth is the way to go,
otherwise there is no way to label the images.

Feature extraction and classification:
- Ideally, we would need a very small (maybe 70KB or less) pre-trained CNN model to do transfer learning
on it as any end-to-end training on the ESP32 is out of the question (both memory-wise and implementation-wise,
as backpropagation and gradient descent would need to be implementeed). Even with quantization and pruning
we weren't able to find one that small. Smallest we could find is the PrunaAI SqueezeNet.
What about implementing and training our own model? Too much of a hassle too as it would require additional
tinkering with tensorflow lite micro and the model wouldn't learn much anyway.
- Solution: extract some features from the image and then train a very simple classifier. Best idea would
be to use some very toned-down HoG-style features
- For classifier, it would be ideal to use a one-layer NN, but that might be too big.
- 2-layer NN with HoG seems to work fine, ignore previous statement as it was made while the project was still
in its infancy.

Further optimizations:
- Tried using async http requests. The ESP library only supports them if HTTPS is used. To avoid using a proper
certificate these variables have to be set in sdkconfig: 'CONFIG_ESP_TLS_INSECURE=y' and
'CONFIG_ESP_TLS_SKIP_SERVER_CERT_VERIFY=y'. Still, the request doesn't work and returns only 'EAGAIN' immediately
every time upon performing the request. Spent a lot of time trying to debug to see what is wrong but to no avail.
At first thought it was a bug having to do with the combination of async and disabled verification, but the issue
is even weirder because it still doesn't work even with verification enabled. Upon further debugging, it seems
the issue comes from line 1448 in esp_http_client.c where the function esp_transport_connect_async is called.
This in turn calls an underlying internal function '_connect_async' which seems to be builtin and inaccessible.
So the issue is probably a bug of the implementation for the heltec lora v3 board.

General consensus: An ESP32-CAM featuring the PSRAM (also known as SPIRAM) module would have been able to achieve
much more, and way fewer compromises would have been made

MQTT:
- QOS 2 is the best option. QOS 1 would be the worst because we don't want to send
duplicate weights for sure. QOS 0 would also work but since the board worked so hard to update the weights anyway,
let's make sure they get to the server. Problem is, with QOS 1 and 2, the outbound messages are stored in an
outbox until sent which uses up too much memory, so we will make do with QOS 0.
- To make sure model doesn't get updated during gradient descent and vice-versa, synchronization is used. This is
done optimally (from the prerspective of both code size and efficiency) and explained in the code through comments
(see MQTT event handler and train task sections). Currently, for choice of simplicity, images received during model
update are just discarded (IDEA: while model is being updated, stop taking photos and basically halt all code).